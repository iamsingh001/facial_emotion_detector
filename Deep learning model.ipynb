{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYR4uG2IR8BH"
      },
      "source": [
        "from keras.layers import Dense,Activation,Dropout,Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.activations import softmax,relu\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.activations import sigmoid"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDesfZ0OR8-p"
      },
      "source": [
        "df=pd.read_csv('fer2013.csv')"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNZA0gmW7ldZ"
      },
      "source": [
        "x_train,x_test,y_train,y_test = [],[],[],[]\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "    val = row['pixels'].split()\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "            x_train.append(np.array(val,'float32'))\n",
        "            y_train.append(row['emotion'])\n",
        "        elif 'PublicTest' or 'PrivateTest' in row['Usage']:\n",
        "            x_test.append(np.array(val,'float32'))\n",
        "            y_test.append(row['emotion'])\n",
        "    except:\n",
        "        None"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcXWnQTK7rEh"
      },
      "source": [
        "# converting values into array because input should be in array only\n",
        "x_train = np.array(x_train,'float32')\n",
        "x_test = np.array(x_test,'float32')\n",
        "y_train = np.array(y_train,'float32')\n",
        "y_test = np.array(y_test,'float32')"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvHToeTX7uh4"
      },
      "source": [
        "#normalizing values between 0 and 1\n",
        "x_train = x_train-np.mean(x_train,axis=0)\n",
        "x_train = x_train/np.std(x_test,axis=0)\n",
        "\n",
        "x_test = x_test-np.mean(x_test,axis=0)\n",
        "x_test = x_test/np.std(x_test,axis=0)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxWjXydZ7wLd"
      },
      "source": [
        "# reshaping data into according to input format\n",
        "x_train = x_train.reshape(x_train.shape[0],48,48,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],48,48,1)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXrnl5RL0u7e",
        "outputId": "c603a81a-6f27-4414-8b51-e76bf396fd93"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sqhn6aE7947"
      },
      "source": [
        " !pip install -q -U keras-tuner"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-NCddw374Mn"
      },
      "source": [
        "from kerastuner import RandomSearch\n",
        "from kerastuner import HyperParameters"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvanmAkA77L6"
      },
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Conv2D(\n",
        "        filters=hp.Int('filters_1',min_value=64,max_value=128,step=16),\n",
        "        kernel_size=hp.Choice('kernel_1', values=[3,5]),\n",
        "        activation='relu',\n",
        "        input_shape=(48, 48, 1)\n",
        "        \n",
        "    ),\n",
        "    MaxPooling2D(pool_size=(2,2),strides=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "    \n",
        "    #adding second layer to the network\n",
        "    Conv2D(\n",
        "        filters=hp.Int('filters_1',min_value=64,max_value=128,step=16),\n",
        "        kernel_size=hp.Choice('kernel_1', values=[3,5]),\n",
        "        activation='relu'\n",
        "        ),\n",
        "        MaxPooling2D(pool_size=(2,2),strides=(2, 2)),\n",
        "        Dropout(0.4),\n",
        "    \n",
        "    #adding 3rd layer to the network\n",
        "    Conv2D(\n",
        "        filters=hp.Int('filters_1',min_value=64,max_value=128,step=16),\n",
        "        kernel_size=hp.Choice('kernel_1', values=[3,5]),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    MaxPooling2D(pool_size=(2,2),strides=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "    \n",
        "    #adding flatten layer\n",
        "    Flatten(),\n",
        "    \n",
        "    #adding dense layer to the network\n",
        "    Dense(\n",
        "        units=hp.Int('units',min_value=2*128,max_value=4*128,step=36),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    #adding dense layer\n",
        "    Dense(\n",
        "        units=hp.Int('units',min_value=2*128,max_value=4*128,step=36),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    #adding last dense layer\n",
        "    Dense(7,activation='softmax')])\n",
        "    \n",
        "    #compiling the model\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJA7kSFvZpAa"
      },
      "source": [
        "tuner_search = RandomSearch(build_model,\n",
        "                            objective='val_accuracy',\n",
        "                            max_trials = 8,directory='output_build_model')"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o49Y745zZ2Wf",
        "outputId": "43ff2d87-fd3f-4811-90cb-fdcbc291eebc"
      },
      "source": [
        "tuner_search.search(x_train,y_train,epochs=30,validation_split=0.1)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 8 Complete [00h 04m 06s]\n",
            "val_accuracy: 0.5715778470039368\n",
            "\n",
            "Best val_accuracy So Far: 0.6105886697769165\n",
            "Total elapsed time: 00h 33m 09s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlQT29GeaLsJ"
      },
      "source": [
        "model= tuner_search.get_best_models(num_models=1)[0]"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ATWKozaOOF",
        "outputId": "1c9ec3e4-918c-4bb2-b834-a46b8dedc825"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 46, 46, 96)        960       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 23, 23, 96)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 23, 23, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 96)        83040     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 96)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 10, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 96)          83040     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 508)               780796    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 508)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 508)               258572    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 508)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 3563      \n",
            "=================================================================\n",
            "Total params: 1,209,971\n",
            "Trainable params: 1,209,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtEcg-X3amT2"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=11,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "call_backs = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJN3gHaU8c6z"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "img_data_gen = ImageDataGenerator(\n",
        "     rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True\n",
        "                \n",
        "                )\n",
        "img_data_gen.fit(x_train)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgLeRgz78f_v",
        "outputId": "6170a4db-2078-46a5-da19-8511aea8dea8"
      },
      "source": [
        "batch_size=32\n",
        "epochs=100\n",
        "\n",
        "history = model.fit(x_train,y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                   callbacks=call_backs,\n",
        "                   validation_data=(x_test,y_test),\n",
        "                   use_multiprocessing=True\n",
        "                   )"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "898/898 [==============================] - 10s 11ms/step - loss: 1.0366 - accuracy: 0.6087 - val_loss: 1.0889 - val_accuracy: 0.5924\n",
            "Epoch 2/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.0224 - accuracy: 0.6148 - val_loss: 1.0852 - val_accuracy: 0.5950\n",
            "Epoch 3/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.0010 - accuracy: 0.6252 - val_loss: 1.0880 - val_accuracy: 0.5940\n",
            "Epoch 4/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 1.0020 - accuracy: 0.6231 - val_loss: 1.1007 - val_accuracy: 0.5940\n",
            "Epoch 5/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9922 - accuracy: 0.6275 - val_loss: 1.0955 - val_accuracy: 0.5926\n",
            "Epoch 6/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9801 - accuracy: 0.6336 - val_loss: 1.0892 - val_accuracy: 0.5952\n",
            "Epoch 7/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9711 - accuracy: 0.6357 - val_loss: 1.0876 - val_accuracy: 0.5996\n",
            "Epoch 8/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9615 - accuracy: 0.6335 - val_loss: 1.0951 - val_accuracy: 0.5960\n",
            "Epoch 9/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9722 - accuracy: 0.6337 - val_loss: 1.0841 - val_accuracy: 0.6016\n",
            "Epoch 10/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9576 - accuracy: 0.6388 - val_loss: 1.0780 - val_accuracy: 0.5995\n",
            "Epoch 11/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9504 - accuracy: 0.6419 - val_loss: 1.1015 - val_accuracy: 0.5953\n",
            "Epoch 12/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9566 - accuracy: 0.6434 - val_loss: 1.0885 - val_accuracy: 0.5978\n",
            "Epoch 13/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9494 - accuracy: 0.6471 - val_loss: 1.0859 - val_accuracy: 0.5995\n",
            "Epoch 14/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9251 - accuracy: 0.6527 - val_loss: 1.0933 - val_accuracy: 0.5995\n",
            "Epoch 15/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9357 - accuracy: 0.6499 - val_loss: 1.0953 - val_accuracy: 0.5984\n",
            "Epoch 16/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9050 - accuracy: 0.6652 - val_loss: 1.0862 - val_accuracy: 0.5960\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 17/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8790 - accuracy: 0.6720 - val_loss: 1.0721 - val_accuracy: 0.6116\n",
            "Epoch 18/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8401 - accuracy: 0.6859 - val_loss: 1.0796 - val_accuracy: 0.6085\n",
            "Epoch 19/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8430 - accuracy: 0.6880 - val_loss: 1.0826 - val_accuracy: 0.6073\n",
            "Epoch 20/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8373 - accuracy: 0.6877 - val_loss: 1.0871 - val_accuracy: 0.6073\n",
            "Epoch 21/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8266 - accuracy: 0.6939 - val_loss: 1.0818 - val_accuracy: 0.6099\n",
            "Epoch 22/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7946 - accuracy: 0.7030 - val_loss: 1.0927 - val_accuracy: 0.6091\n",
            "Epoch 23/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8106 - accuracy: 0.6977 - val_loss: 1.0958 - val_accuracy: 0.6163\n",
            "Epoch 24/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7847 - accuracy: 0.7090 - val_loss: 1.0853 - val_accuracy: 0.6095\n",
            "Epoch 25/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7789 - accuracy: 0.7102 - val_loss: 1.0849 - val_accuracy: 0.6102\n",
            "Epoch 26/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7713 - accuracy: 0.7129 - val_loss: 1.0679 - val_accuracy: 0.6148\n",
            "Epoch 27/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7666 - accuracy: 0.7159 - val_loss: 1.0635 - val_accuracy: 0.6186\n",
            "Epoch 28/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7654 - accuracy: 0.7163 - val_loss: 1.0862 - val_accuracy: 0.6110\n",
            "Epoch 29/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7620 - accuracy: 0.7135 - val_loss: 1.0858 - val_accuracy: 0.6165\n",
            "Epoch 30/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7490 - accuracy: 0.7195 - val_loss: 1.0810 - val_accuracy: 0.6197\n",
            "Epoch 31/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7470 - accuracy: 0.7234 - val_loss: 1.0800 - val_accuracy: 0.6198\n",
            "Epoch 32/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7361 - accuracy: 0.7273 - val_loss: 1.0864 - val_accuracy: 0.6174\n",
            "Epoch 33/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7360 - accuracy: 0.7253 - val_loss: 1.0671 - val_accuracy: 0.6187\n",
            "Epoch 34/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7319 - accuracy: 0.7260 - val_loss: 1.0660 - val_accuracy: 0.6154\n",
            "Epoch 35/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7219 - accuracy: 0.7337 - val_loss: 1.0782 - val_accuracy: 0.6205\n",
            "Epoch 36/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7160 - accuracy: 0.7351 - val_loss: 1.0864 - val_accuracy: 0.6206\n",
            "Epoch 37/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7181 - accuracy: 0.7316 - val_loss: 1.0826 - val_accuracy: 0.6223\n",
            "Epoch 38/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7197 - accuracy: 0.7350 - val_loss: 1.1114 - val_accuracy: 0.6188\n",
            "Epoch 39/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.7081 - accuracy: 0.7336 - val_loss: 1.1007 - val_accuracy: 0.6149\n",
            "Epoch 40/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6888 - accuracy: 0.7444 - val_loss: 1.0907 - val_accuracy: 0.6225\n",
            "Epoch 41/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7033 - accuracy: 0.7410 - val_loss: 1.0803 - val_accuracy: 0.6195\n",
            "Epoch 42/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6837 - accuracy: 0.7455 - val_loss: 1.1095 - val_accuracy: 0.6167\n",
            "Epoch 43/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6910 - accuracy: 0.7454 - val_loss: 1.0989 - val_accuracy: 0.6234\n",
            "Epoch 44/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6783 - accuracy: 0.7468 - val_loss: 1.0943 - val_accuracy: 0.6184\n",
            "Epoch 45/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6719 - accuracy: 0.7502 - val_loss: 1.1012 - val_accuracy: 0.6197\n",
            "Epoch 46/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6775 - accuracy: 0.7517 - val_loss: 1.0980 - val_accuracy: 0.6167\n",
            "Epoch 47/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6629 - accuracy: 0.7534 - val_loss: 1.0949 - val_accuracy: 0.6179\n",
            "Epoch 48/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6798 - accuracy: 0.7509 - val_loss: 1.0965 - val_accuracy: 0.6219\n",
            "Epoch 49/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6738 - accuracy: 0.7541 - val_loss: 1.1140 - val_accuracy: 0.6177\n",
            "Epoch 50/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6627 - accuracy: 0.7569 - val_loss: 1.0988 - val_accuracy: 0.6176\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 51/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6502 - accuracy: 0.7612 - val_loss: 1.1115 - val_accuracy: 0.6240\n",
            "Epoch 52/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6202 - accuracy: 0.7699 - val_loss: 1.1054 - val_accuracy: 0.6257\n",
            "Epoch 53/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6106 - accuracy: 0.7735 - val_loss: 1.1077 - val_accuracy: 0.6245\n",
            "Epoch 54/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6046 - accuracy: 0.7762 - val_loss: 1.1120 - val_accuracy: 0.6248\n",
            "Epoch 55/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6190 - accuracy: 0.7737 - val_loss: 1.1163 - val_accuracy: 0.6234\n",
            "Epoch 56/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6029 - accuracy: 0.7738 - val_loss: 1.1208 - val_accuracy: 0.6202\n",
            "Epoch 57/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5991 - accuracy: 0.7788 - val_loss: 1.1290 - val_accuracy: 0.6229\n",
            "Epoch 58/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5900 - accuracy: 0.7836 - val_loss: 1.1175 - val_accuracy: 0.6272\n",
            "Epoch 59/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5919 - accuracy: 0.7820 - val_loss: 1.1301 - val_accuracy: 0.6259\n",
            "Epoch 60/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5846 - accuracy: 0.7831 - val_loss: 1.1175 - val_accuracy: 0.6208\n",
            "Epoch 61/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5732 - accuracy: 0.7899 - val_loss: 1.1213 - val_accuracy: 0.6266\n",
            "Epoch 62/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5838 - accuracy: 0.7870 - val_loss: 1.1269 - val_accuracy: 0.6226\n",
            "Epoch 63/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5713 - accuracy: 0.7928 - val_loss: 1.1264 - val_accuracy: 0.6229\n",
            "Epoch 64/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5747 - accuracy: 0.7900 - val_loss: 1.1227 - val_accuracy: 0.6245\n",
            "Epoch 65/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5526 - accuracy: 0.7969 - val_loss: 1.1330 - val_accuracy: 0.6252\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 66/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5607 - accuracy: 0.7936 - val_loss: 1.1294 - val_accuracy: 0.6304\n",
            "Epoch 67/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5449 - accuracy: 0.8034 - val_loss: 1.1355 - val_accuracy: 0.6269\n",
            "Epoch 68/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5506 - accuracy: 0.7947 - val_loss: 1.1261 - val_accuracy: 0.6312\n",
            "Epoch 69/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5299 - accuracy: 0.8046 - val_loss: 1.1299 - val_accuracy: 0.6298\n",
            "Epoch 70/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5401 - accuracy: 0.7995 - val_loss: 1.1375 - val_accuracy: 0.6317\n",
            "Epoch 71/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5404 - accuracy: 0.7964 - val_loss: 1.1375 - val_accuracy: 0.6286\n",
            "Epoch 72/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5227 - accuracy: 0.8094 - val_loss: 1.1365 - val_accuracy: 0.6283\n",
            "Epoch 73/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5237 - accuracy: 0.8081 - val_loss: 1.1394 - val_accuracy: 0.6308\n",
            "Epoch 74/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5302 - accuracy: 0.8060 - val_loss: 1.1280 - val_accuracy: 0.6321\n",
            "Epoch 75/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5364 - accuracy: 0.8036 - val_loss: 1.1350 - val_accuracy: 0.6259\n",
            "Epoch 76/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5133 - accuracy: 0.8134 - val_loss: 1.1316 - val_accuracy: 0.6308\n",
            "Epoch 77/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5321 - accuracy: 0.8038 - val_loss: 1.1329 - val_accuracy: 0.6304\n",
            "Epoch 78/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5259 - accuracy: 0.8068 - val_loss: 1.1495 - val_accuracy: 0.6303\n",
            "Epoch 79/100\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5128 - accuracy: 0.8109 - val_loss: 1.1458 - val_accuracy: 0.6300\n",
            "Epoch 80/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5248 - accuracy: 0.8060 - val_loss: 1.1300 - val_accuracy: 0.6297\n",
            "Epoch 81/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5100 - accuracy: 0.8141 - val_loss: 1.1503 - val_accuracy: 0.6310\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 82/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5080 - accuracy: 0.8139 - val_loss: 1.1478 - val_accuracy: 0.6311\n",
            "Epoch 83/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5127 - accuracy: 0.8129 - val_loss: 1.1466 - val_accuracy: 0.6308\n",
            "Epoch 84/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5039 - accuracy: 0.8139 - val_loss: 1.1470 - val_accuracy: 0.6268\n",
            "Epoch 85/100\n",
            "898/898 [==============================] - 9s 11ms/step - loss: 0.5058 - accuracy: 0.8133 - val_loss: 1.1504 - val_accuracy: 0.6279\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00085: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AasTqBTG8hyR"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATH6sbTi7AhH"
      },
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GfjSxBc8BT5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}